{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = st.secrets["OPENAI_API_KEY"]
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.4.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Connect to Weaviate Retriever and configure LLM\n",
    "import dspy\n",
    "from dspy.retrieve.weaviate_rm import WeaviateRM\n",
    "import weaviate\n",
    "import openai\n",
    "\n",
    "\n",
    "llm = dspy.OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# ollamaLLM = dspy.OpenAI(api_base=\"http://localhost:11434/v1/\", api_key=\"ollama\", model=\"mistral-7b-instruct-v0.2-q6_K\", stop='\\n\\n', model_type='chat')\n",
    "# Thanks Knox! https://twitter.com/JR_Knox1977/status/1756018720818794916/photo/1\n",
    "\n",
    "weaviate_client = weaviate.Client(\"http://localhost:8080\")\n",
    "retriever_model = WeaviateRM(\"WeaviateBlogChunk\", weaviate_client=weaviate_client)\n",
    "# Assumes the Weaviate collection has a text key `content`\n",
    "dspy.settings.configure(lm=llm, rm=retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How much work do you believe is necessary when starting a company, based on your experience?',\n",
       " 'Could you share how you and your brother managed to save money in the early days of Zip2?',\n",
       " 'Why do you think it\\'s crucial to work \"super hard\" in the early stages of a startup?',\n",
       " 'Can you explain the advantage of working 100 hours a week over 50 with a mathematical perspective?',\n",
       " 'Could you describe a pivotal financial decision you had to make for both SpaceX and Tesla?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load FAQs\n",
    "import re\n",
    "\n",
    "f = open(\"faq.md\")\n",
    "markdown_content = f.read()\n",
    "\n",
    "def parse_questions(markdown_content):\n",
    "    # Regular expression pattern for finding questions\n",
    "    question_pattern = r'#### Q: (.+?)\\n'\n",
    "\n",
    "    # Finding all questions\n",
    "    questions = re.findall(question_pattern, markdown_content, re.DOTALL)\n",
    "\n",
    "    return questions\n",
    "\n",
    "# Parsing the markdown content to get only questions\n",
    "questions = parse_questions(markdown_content)\n",
    "\n",
    "# Displaying the first few extracted questions\n",
    "questions[:5]  # Displaying only the first few for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (4.10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# ToDo, add random splitting -- maybe wrap this entire thing in a cross-validation loop\n",
    "trainset = questions[:20] # 20 examples for training\n",
    "devset = questions[20:30] # 10 examples for development\n",
    "testset = questions[30:] # 14 examples for testing\n",
    "\n",
    "trainset = [dspy.Example(question=question).with_inputs(\"question\") for question in trainset]\n",
    "devset = [dspy.Example(question=question).with_inputs(\"question\") for question in devset]\n",
    "testset = [dspy.Example(question=question).with_inputs(\"question\") for question in testset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'What do you perceive as your personal chances of going to Mars?'}) (input_keys={'question'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a WIP, the next step is to optimize this metric as itself a DSPy module (pretty meta)\n",
    "\n",
    "# Reference - https://github.com/stanfordnlp/dspy/blob/main/examples/tweets/tweet_metric.py\n",
    "\n",
    "metricLM = dspy.OpenAI(model='gpt-4', max_tokens=1000, model_type='chat')\n",
    "\n",
    "# Signature for LLM assessments.\n",
    "\n",
    "class Assess(dspy.Signature):\n",
    "    \"\"\"Assess the quality of an answer to a question.\"\"\"\n",
    "    \n",
    "    context = dspy.InputField(desc=\"The context for answering the question.\")\n",
    "    assessed_question = dspy.InputField(desc=\"The evaluation criterion.\")\n",
    "    assessed_answer = dspy.InputField(desc=\"The answer to the question.\")\n",
    "    assessment_answer = dspy.OutputField(desc=\"A rating between 1 and 5. Only output the rating and nothing else.\")\n",
    "\n",
    "def llm_metric(gold, pred, trace=None):\n",
    "    predicted_answer = pred.answer\n",
    "    question = gold.question\n",
    "    \n",
    "    print(f\"Test Question: {question}\")\n",
    "    print(f\"Predicted Answer: predicted_answer\")\n",
    "    \n",
    "    detail = \"Is the assessed answer detailed?\"\n",
    "    faithful = \"Is the assessed text grounded in the context? Say no if it includes significant facts not in the context.\"\n",
    "    overall = f\"Please rate how well this answer answers the question, `{question}` based on the context.\\n `{predicted_answer}`\"\n",
    "    \n",
    "    with dspy.context(lm=metricLM):\n",
    "        context = dspy.Retrieve(k=5)(question).passages\n",
    "        detail = dspy.ChainOfThought(Assess)(context=\"N/A\", assessed_question=detail, assessed_answer=predicted_answer)\n",
    "        faithful = dspy.ChainOfThought(Assess)(context=context, assessed_question=faithful, assessed_answer=predicted_answer)\n",
    "        overall = dspy.ChainOfThought(Assess)(context=context, assessed_question=overall, assessed_answer=predicted_answer)\n",
    "    \n",
    "    print(f\"Faithful: {faithful.assessment_answer}\")\n",
    "    print(f\"Detail: {detail.assessment_answer}\")\n",
    "    print(f\"Overall: {overall.assessment_answer}\")\n",
    "    \n",
    "    \n",
    "    total = float(detail.assessment_answer) + float(faithful.assessment_answer)*2 + float(overall.assessment_answer)\n",
    "    \n",
    "    return total / 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: What drives Tesla's innovation in electric vehicles?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 3\n",
      "Detail: 1\n",
      "Overall: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = dspy.Example(question=\"What drives Tesla's innovation in electric vehicles?\")\n",
    "test_pred = dspy.Example(answer=\"Pushing boundaries for sustainable transport solutions\")\n",
    "\n",
    "type(llm_metric(test_example, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Assess the quality of an answer to a question.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: The context for answering the question.\n",
      "\n",
      "Assessed Question: The evaluation criterion.\n",
      "\n",
      "Assessed Answer: The answer to the question.\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the assessment_answer}. We ...\n",
      "\n",
      "Assessment Answer: A rating between 1 and 5. Only output the rating and nothing else.\n",
      "\n",
      "---\n",
      "\n",
      "Context: N/A\n",
      "\n",
      "Assessed Question: Is the assessed answer detailed?\n",
      "\n",
      "Assessed Answer: Pushing boundaries for sustainable transport solutions\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the assessment answer. We need to consider if the answer provides enough detail to fully answer the question. In this case, the answer is very vague and does not provide any specific details about how boundaries are being pushed for sustainable transport solutions. \n",
      "\n",
      "Assessment Answer: 1\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Assess the quality of an answer to a question.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: The context for answering the question.\n",
      "\n",
      "Assessed Question: The evaluation criterion.\n",
      "\n",
      "Assessed Answer: The answer to the question.\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the assessment_answer}. We ...\n",
      "\n",
      "Assessment Answer: A rating between 1 and 5. Only output the rating and nothing else.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «On the Tesla front, the goal with Tesla was really to try to show what electric cars can do because people had the wrong impression. We had to change people's perception of an electric vehicle because they used to think of it as something that was slow and ugly and had low range, kind of like a golf cart. So that's why we created the Tesla Roadster to show that you can be fast, attractive and long range. And it's amazing how even though you can show that something works on paper, and the calculations are very clear, until you actually have the physical object and they can drive it, it doesn't really sink in for people. And so that I think is something worth noting.»\n",
      "[2] «Actually, at the time in college, I sort of thought helping with electrification of cars was how I would start out. And that's actually what I worked on as an intern, was advanced ultra capacitors, to see if there would be a breakthrough relative to batteries for energy storage in cars. And then when I came out to go to Stanford, that's what I was going to be doing my grad studies on, is was working on advanced energy storage technologies for electric cars. And then I put that on hold to start an internet company in 95 because there does seem to be like a time for particular technologies when they're at a steep point in the inflection curve. And I didn't want to do a PhD at Stanford and then watch it all happen.»\n",
      "[3] «Engineering and design, so it's developing next generation product, that's 80% of it. I think a lot of people think I'm kind of a business person or something, which is fine, business is fine, but really it's, it's like it's SpaceX, Gwynne Shotwell is chief operating officer, she kind of manages legal, finance, sales, and kind of general business activity, and then my time is almost entirely with the engineering team working on improving the Falcon 9 and the Dragon spacecraft and developing the Mars Colonial Architecture. And then at Tesla it's working on the Model 3 and some in the design studio typically half a day a week, dealing with aesthetics and look and feel things and then most of the rest of the week is just going through engineering of the car itself as well as engineering of the factory. Because the biggest epiphany I've had is that what really matters is the is the machine that builds the machine the factory and this is that is at least tours magnitude harder than the vehicle itself what are the scenarios that scare you most humanity really is not evolved to think of existential threats in general we're involved to think about things that are very close to us, near term, to be upset with other humans and not really to think about things that could destroy humanity as a whole. But then in recent decades, just really in the last century, we had nuclear bombs, which could potentially destroy civilization, obviously.»\n",
      "[4] «So I originally came out to California to try to figure out how to improve the energy density of electric vehicles, basically to try to figure out if there was an advanced capacitor that could serve as an alternative to batteries. And that was in 95, and that's also when the internet started to happen. And I thought, well, I can either pursue this technology where success may not be one of the possible outcomes, which is always tricky, or participate in the internet and be part of it. And I think maybe it's helpful to say one of the things that was important then in the creation of PayPal was kind of how it started. Because initially, the initial thought with PayPal was to create an agglomeration of financial services so that you have one place where all your financial services needs would be seamlessly integrated and work smoothly.»\n",
      "[5] «Tesla still has yet to turn a profit. That'd be a $1.5 billion company with no profit. Its most recent quarter actually lost more money than it did the year before, $1.5 billion, losing more money than the year before. This is a company with limited visibility. You put $90 billion, like 50 years worth of brakes, into solar and wind, to Solyndra and Fisker and Tesla and Ener1.»\n",
      "\n",
      "Assessed Question: Is the assessed text grounded in the context? Say no if it includes significant facts not in the context.\n",
      "\n",
      "Assessed Answer: Pushing boundaries for sustainable transport solutions\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the assessment answer. The assessed answer \"Pushing boundaries for sustainable transport solutions\" is a general statement that could be inferred from the context provided. The context discusses the speaker's efforts in developing electric vehicles and advanced energy storage technologies, which can be seen as pushing boundaries for sustainable transport solutions. However, the assessed answer does not include any specific facts or details from the context.\n",
      "\n",
      "Assessment Answer: 3\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Assess the quality of an answer to a question.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: The context for answering the question.\n",
      "\n",
      "Assessed Question: The evaluation criterion.\n",
      "\n",
      "Assessed Answer: The answer to the question.\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the assessment_answer}. We ...\n",
      "\n",
      "Assessment Answer: A rating between 1 and 5. Only output the rating and nothing else.\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «On the Tesla front, the goal with Tesla was really to try to show what electric cars can do because people had the wrong impression. We had to change people's perception of an electric vehicle because they used to think of it as something that was slow and ugly and had low range, kind of like a golf cart. So that's why we created the Tesla Roadster to show that you can be fast, attractive and long range. And it's amazing how even though you can show that something works on paper, and the calculations are very clear, until you actually have the physical object and they can drive it, it doesn't really sink in for people. And so that I think is something worth noting.»\n",
      "[2] «Actually, at the time in college, I sort of thought helping with electrification of cars was how I would start out. And that's actually what I worked on as an intern, was advanced ultra capacitors, to see if there would be a breakthrough relative to batteries for energy storage in cars. And then when I came out to go to Stanford, that's what I was going to be doing my grad studies on, is was working on advanced energy storage technologies for electric cars. And then I put that on hold to start an internet company in 95 because there does seem to be like a time for particular technologies when they're at a steep point in the inflection curve. And I didn't want to do a PhD at Stanford and then watch it all happen.»\n",
      "[3] «Engineering and design, so it's developing next generation product, that's 80% of it. I think a lot of people think I'm kind of a business person or something, which is fine, business is fine, but really it's, it's like it's SpaceX, Gwynne Shotwell is chief operating officer, she kind of manages legal, finance, sales, and kind of general business activity, and then my time is almost entirely with the engineering team working on improving the Falcon 9 and the Dragon spacecraft and developing the Mars Colonial Architecture. And then at Tesla it's working on the Model 3 and some in the design studio typically half a day a week, dealing with aesthetics and look and feel things and then most of the rest of the week is just going through engineering of the car itself as well as engineering of the factory. Because the biggest epiphany I've had is that what really matters is the is the machine that builds the machine the factory and this is that is at least tours magnitude harder than the vehicle itself what are the scenarios that scare you most humanity really is not evolved to think of existential threats in general we're involved to think about things that are very close to us, near term, to be upset with other humans and not really to think about things that could destroy humanity as a whole. But then in recent decades, just really in the last century, we had nuclear bombs, which could potentially destroy civilization, obviously.»\n",
      "[4] «So I originally came out to California to try to figure out how to improve the energy density of electric vehicles, basically to try to figure out if there was an advanced capacitor that could serve as an alternative to batteries. And that was in 95, and that's also when the internet started to happen. And I thought, well, I can either pursue this technology where success may not be one of the possible outcomes, which is always tricky, or participate in the internet and be part of it. And I think maybe it's helpful to say one of the things that was important then in the creation of PayPal was kind of how it started. Because initially, the initial thought with PayPal was to create an agglomeration of financial services so that you have one place where all your financial services needs would be seamlessly integrated and work smoothly.»\n",
      "[5] «Tesla still has yet to turn a profit. That'd be a $1.5 billion company with no profit. Its most recent quarter actually lost more money than it did the year before, $1.5 billion, losing more money than the year before. This is a company with limited visibility. You put $90 billion, like 50 years worth of brakes, into solar and wind, to Solyndra and Fisker and Tesla and Ener1.»\n",
      "\n",
      "Assessed Question: Please rate how well this answer answers the question, `What drives Tesla's innovation in electric vehicles?` based on the context. `Pushing boundaries for sustainable transport solutions`\n",
      "\n",
      "Assessed Answer: Pushing boundaries for sustainable transport solutions\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the assessment answer. We can see from the context that Tesla's innovation in electric vehicles is driven by a desire to change people's perception of electric vehicles, as stated in [1]. The company aims to show that electric cars can be fast, attractive, and have a long range. Furthermore, the founder of Tesla, Elon Musk, has a background in engineering and design, and he spends most of his time working on improving the vehicles and the factory that builds them, as mentioned in [3]. This shows that Tesla is indeed pushing boundaries for sustainable transport solutions. However, the assessed answer could have been more detailed and specific in explaining how Tesla is pushing these boundaries.\n",
      "\n",
      "Assessment Answer: 4\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metricLM.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions based on the context.\"\"\"\n",
    "    \n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "        self.rerank = dspy.Predict(\"question, context -> reranked_context\")\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        context = self.rerank(question=question, context=context).reranked_context\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "\n",
    "        return dspy.Prediction(answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions based on the context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What drives Tesla's innovation in electric vehicles?\n",
      "Answer:\u001b[32m Context: Tesla is known for its innovation in electric vehicles, constantly pushing the boundaries of technology and design.\n",
      "Question: What drives Tesla's innovation in electric vehicles?\n",
      "Answer: Tesla's innovation in electric vehicles is driven by their focus on sustainability, cutting-edge technology, and commitment to reducing carbon emissions in the transportation sector.\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.Predict(GenerateAnswer)(question=\"What drives Tesla's innovation in electric vehicles?\")\n",
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions based on the context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "produce the answer. We know that Tesla is known for its innovation in electric vehicles, constantly pushing the boundaries of technology in this industry. They invest heavily in research and development, focusing on improving battery technology, autonomous driving capabilities, and overall vehicle performance.\n",
      "\n",
      "Answer: Tesla's innovation in electric vehicles is primarily driven by their focus on research and development, particularly in improving battery technology, autonomous driving capabilities, and overall vehicle performance.\n",
      "\n",
      "Question: What drives Tesla's innovation in electric vehicles?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m produce the answer. We know that Tesla is known for its innovation in electric vehicles, constantly pushing the boundaries of technology in this industry. They invest heavily in research and development, focusing on improving battery technology, autonomous driving capabilities, and overall vehicle performance.\n",
      "\n",
      "Answer: Tesla's innovation in electric vehicles is primarily driven by their focus on research and development, particularly in improving battery technology,\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.ChainOfThought(GenerateAnswer)(question=\"What drives Tesla's innovation in electric vehicles?\")\n",
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer=''\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspy.ReAct(GenerateAnswer, tools=[dspy.settings.rm])(question=\"What drives Tesla's innovation in electric vehicles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "You will be given `context`, `question` and you will respond with `answer`.\n",
      "\n",
      "To do this, you will interleave Thought, Action, and Observation steps.\n",
      "\n",
      "Thought can reason about the current situation, and Action can be the following types:\n",
      "\n",
      "(1) Search[query], which takes a search query and returns one or more potentially relevant passages from a corpus\n",
      "(2) Finish[answer], which returns the final `answer` and finishes the task\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Thought 1: next steps to take based on last observation\n",
      "\n",
      "Action 1: always either Search[query] or, when done, Finish[answer]\n",
      "\n",
      "Observation 1: observations based on action\n",
      "\n",
      "Thought 2: next steps to take based on last observation\n",
      "\n",
      "Action 2: always either Search[query] or, when done, Finish[answer]\n",
      "\n",
      "Observation 2: observations based on action\n",
      "\n",
      "Thought 3: next steps to take based on last observation\n",
      "\n",
      "Action 3: always either Search[query] or, when done, Finish[answer]\n",
      "\n",
      "Observation 3: observations based on action\n",
      "\n",
      "Thought 4: next steps to take based on last observation\n",
      "\n",
      "Action 4: always either Search[query] or, when done, Finish[answer]\n",
      "\n",
      "Observation 4: observations based on action\n",
      "\n",
      "Thought 5: next steps to take based on last observation\n",
      "\n",
      "Action 5: always either Search[query] or, when done, Finish[answer]\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "Tesla's innovation in electric vehicles is driven by a combination of factors such as technological advancements, environmental concerns, and consumer demand.\n",
      "\n",
      "Action 1: Search[Tesla's innovation in electric vehicles]\n",
      "\n",
      "Question: What drives Tesla's innovation in electric vehicles?\n",
      "\n",
      "Thought 1: \n",
      "\n",
      "Action 1: Tesla's innovation in electric vehicles is likely driven by a combination of factors such as technological advancements, environmental concerns, and consumer demand. Action 1: Search[Tesla's innovation in electric vehicles]\n",
      "\n",
      "Observation 1: Failed to parse action. Bad formatting or incorrect action name.\n",
      "\n",
      "Thought 2: I need to correct the formatting and search for information on what drives Tesla's innovation in electric vehicles. Action 1: Search[Tesla's innovation in electric vehicles]\n",
      "\n",
      "Action 2: Search[Factors driving Tesla's innovation in electric vehicles]\n",
      "\n",
      "Observation 2: Failed to parse action. Bad formatting or incorrect action name.\n",
      "\n",
      "Thought 3: I need to correct the formatting and search for information on the factors driving Tesla's innovation in electric vehicles. Action 2: Search[Factors driving Tesla's innovation in electric vehicles]\n",
      "\n",
      "Action 3: Search[What factors drive Tesla's innovation in electric vehicles]\n",
      "\n",
      "Observation 3: Failed to parse action. Bad formatting or incorrect action name.\n",
      "\n",
      "Thought 4: I need to correct the formatting and search for information on what factors drive Tesla's innovation in electric vehicles. Action 3: Search[What factors drive Tesla's innovation in electric vehicles]\n",
      "\n",
      "Action 4: Search[Factors influencing Tesla's innovation in electric vehicles]\n",
      "\n",
      "Observation 4: Failed to parse action. Bad formatting or incorrect action name.\n",
      "\n",
      "Thought 5: I need to correct the formatting and search for information on the factors influencing Tesla's innovation in electric vehicles. Action 4: Search[Factors influencing Tesla's innovation in electric vehicles]\n",
      "\n",
      "Action 5:\u001b[32m Search[Factors that influence Tesla's innovation in electric vehicles]\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "llm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla's innovation in electric vehicles is primarily driven by the goal of changing people's perception of electric cars and showing that they can be fast, attractive, and have long range. This drive is also influenced by Elon Musk's background in working on advanced energy storage technologies for electric cars.\n"
     ]
    }
   ],
   "source": [
    "print(uncompiled_rag(\"What drives Tesla's innovation in electric vehicles \").answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: What do you perceive as your personal chances of going to Mars?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.6 / 1  (360.0):  10%|█         | 1/10 [00:15<02:15, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: How do you compare the risks associated with going to Mars to those of climbing Mount Everest?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.0 / 2  (350.0):  20%|██        | 2/10 [00:30<02:04, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 2\n",
      "Overall: 5\n",
      "Test Question: Why is making life multi-planetary essential, in your opinion?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.0 / 3  (366.7):  30%|███       | 3/10 [00:51<02:04, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: How do you defend Tesla's electric vehicle approach against critics?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.4 / 4  (360.0):  40%|████      | 4/10 [01:08<01:46, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 4\n",
      "Overall: 3\n",
      "Test Question: What was the foundational idea behind the creation of PayPal?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.0 / 5  (360.0):  50%|█████     | 5/10 [01:28<01:32, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: What are your thoughts on the future impact of artificial intelligence on society?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.0 / 6  (366.7):  60%|██████    | 6/10 [01:49<01:16, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: How can we minimize the risks associated with the advancement of AI?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.4 / 7  (362.9):  70%|███████   | 7/10 [02:01<00:51, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 4\n",
      "Detail: 5\n",
      "Overall: 4\n",
      "Test Question: Can you share your hiring philosophy and what you look for in team members?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29.4 / 8  (367.5):  80%|████████  | 8/10 [02:18<00:33, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: How important do you think academic degrees are for achieving success?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 32.6 / 9  (362.2):  90%|█████████ | 9/10 [02:34<00:16, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 4\n",
      "Detail: 5\n",
      "Overall: 3\n",
      "Test Question: How do you prioritize innovation within your companies?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.6 / 10  (366.0): 100%|██████████| 10/10 [02:49<00:00, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Average Metric: 36.6 / 10  (366.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/dspy/evaluate/evaluate.py:137: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fb058 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fb058 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_fb058_row0_col0, #T_fb058_row0_col1, #T_fb058_row0_col2, #T_fb058_row1_col0, #T_fb058_row1_col1, #T_fb058_row1_col2, #T_fb058_row2_col0, #T_fb058_row2_col1, #T_fb058_row2_col2, #T_fb058_row3_col0, #T_fb058_row3_col1, #T_fb058_row3_col2, #T_fb058_row4_col0, #T_fb058_row4_col1, #T_fb058_row4_col2 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fb058\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fb058_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_fb058_level0_col1\" class=\"col_heading level0 col1\" >answer</th>\n",
       "      <th id=\"T_fb058_level0_col2\" class=\"col_heading level0 col2\" >llm_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fb058_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fb058_row0_col0\" class=\"data row0 col0\" >What do you perceive as your personal chances of going to Mars?</td>\n",
       "      <td id=\"T_fb058_row0_col1\" class=\"data row0 col1\" >Elon Musk perceives his personal chances of going to Mars as 70%.</td>\n",
       "      <td id=\"T_fb058_row0_col2\" class=\"data row0 col2\" >3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb058_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fb058_row1_col0\" class=\"data row1 col0\" >How do you compare the risks associated with going to Mars to those of climbing Mount Everest?</td>\n",
       "      <td id=\"T_fb058_row1_col1\" class=\"data row1 col1\" >Both climbing Mount Everest and going to Mars have a high chance of death associated with them.</td>\n",
       "      <td id=\"T_fb058_row1_col2\" class=\"data row1 col2\" >3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb058_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fb058_row2_col0\" class=\"data row2 col0\" >Why is making life multi-planetary essential, in your opinion?</td>\n",
       "      <td id=\"T_fb058_row2_col1\" class=\"data row2 col1\" >Making life multi-planetary is essential because it ensures the long-term survival of humanity, provides a sense of adventure and excitement about the future, and serves...</td>\n",
       "      <td id=\"T_fb058_row2_col2\" class=\"data row2 col2\" >4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb058_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fb058_row3_col0\" class=\"data row3 col0\" >How do you defend Tesla's electric vehicle approach against critics?</td>\n",
       "      <td id=\"T_fb058_row3_col1\" class=\"data row3 col1\" >Elon Musk defends Tesla's electric vehicle approach by highlighting the need to change people's perception of electric cars and demonstrating through the Tesla Roadster that...</td>\n",
       "      <td id=\"T_fb058_row3_col2\" class=\"data row3 col2\" >3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fb058_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fb058_row4_col0\" class=\"data row4 col0\" >What was the foundational idea behind the creation of PayPal?</td>\n",
       "      <td id=\"T_fb058_row4_col1\" class=\"data row4 col1\" >The foundational idea behind the creation of PayPal was to create an agglomeration of financial services so that all financial needs could be seamlessly integrated...</td>\n",
       "      <td id=\"T_fb058_row4_col2\" class=\"data row4 col2\" >3.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2d5e1d41c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center; \n",
       "                    font-size: 16px; \n",
       "                    font-weight: bold; \n",
       "                    color: #555; \n",
       "                    margin: 10px 0;'>\n",
       "                    ... 5 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "366.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "evaluate = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n",
    "\n",
    "evaluate(RAG(), metric=llm_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: How much work do you believe is necessary when starting a company, based on your experience?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:23<07:18, 23.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: Could you share how you and your brother managed to save money in the early days of Zip2?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:41<06:04, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 1\n",
      "Detail: 5\n",
      "Overall: 3\n",
      "Test Question: Why do you think it's crucial to work \"super hard\" in the early stages of a startup?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:57<05:12, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 4\n",
      "Overall: 5\n",
      "Test Question: Can you explain the advantage of working 100 hours a week over 50 with a mathematical perspective?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [01:16<05:04, 19.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 1 examples in round 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "teleprompter = BootstrapFewShot(metric = llm_metric, max_labeled_demos=8, max_rounds=3)\n",
    "compiled_rag = teleprompter.compile(uncompiled_rag, trainset=trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: How can we minimize the risks associated with the advancement of AI?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:17<02:36, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: How important do you think academic degrees are for achieving success?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:35<02:22, 17.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 3\n",
      "Detail: 5\n",
      "Overall: 3\n",
      "Test Question: How do you prioritize innovation within your companies?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:53<02:03, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: Can you share your hiring philosophy and what you look for in team members?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:12<01:48, 18.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: What are your thoughts on the future impact of artificial intelligence on society?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:23<03:33, 23.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: How do you prioritize innovation within your companies?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:24<01:19,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: How do you defend Tesla's electric vehicle approach against critics?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:42<01:37, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Test Question: What was the foundational idea behind the creation of PayPal?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:55<01:23, 13.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: How do you compare the risks associated with going to Mars to those of climbing Mount Everest?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:51, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: N/A\n",
      "Overall: 5\n",
      "Failed to run or to evaluate example Example({'question': 'How do you compare the risks associated with going to Mars to those of climbing Mount Everest?'}) (input_keys={'question'}) with <function llm_metric at 0x7f2dc84a7400> due to could not convert string to float: 'N/A'.\n",
      "Test Question: What are your thoughts on the future impact of artificial intelligence on society?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:19<01:04,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: How can we minimize the risks associated with the advancement of AI?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:19<00:31,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: What do you perceive as your personal chances of going to Mars?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:33<00:49,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n",
      "Test Question: How do you prioritize innovation within your companies?\n",
      "Predicted Answer: predicted_answer\n",
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:34<00:34,  6.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: How important do you think academic degrees are for achieving success?\n",
      "Predicted Answer: predicted_answer\n",
      "Faithful: 3\n",
      "Detail: 5\n",
      "Overall: 3\n",
      "Test Question: Why is making life multi-planetary essential, in your opinion?\n",
      "Predicted Answer: predicted_answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:17<01:23, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:18<00:41,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: What do you perceive as your personal chances of going to Mars?\n",
      "Predicted Answer: predicted_answer\n",
      "Faithful: 5\n",
      "Detail: 3\n",
      "Overall: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:18<00:27,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question: Can you share your hiring philosophy and what you look for in team members?\n",
      "Predicted Answer: predicted_answer\n",
      "Faithful: 5\n",
      "Detail: 5\n",
      "Overall: 5\n",
      "Bootstrapped 4 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Predict' object has no attribute 'extended_signature1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m teleprompter \u001b[38;5;241m=\u001b[39m BayesianSignatureOptimizer(task_model\u001b[38;5;241m=\u001b[39mdspy\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mlm,\n\u001b[1;32m      5\u001b[0m                                         metric \u001b[38;5;241m=\u001b[39m llm_metric,\n\u001b[1;32m      6\u001b[0m                                         prompt_model\u001b[38;5;241m=\u001b[39mllm_prompter,\n\u001b[1;32m      7\u001b[0m                                         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      8\u001b[0m                                         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, display_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m third_compiled_rag \u001b[38;5;241m=\u001b[39m \u001b[43mteleprompter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptuna_trials_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_bootstrapped_demos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmax_labeled_demos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                \u001b[49m\u001b[43meval_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/dspy/teleprompt/signature_opt_bayesian.py:311\u001b[0m, in \u001b[0;36mBayesianSignatureOptimizer.compile\u001b[0;34m(self, student, devset, optuna_trials_num, max_bootstrapped_demos, max_labeled_demos, eval_kwargs, seed, view_data, view_examples)\u001b[0m\n\u001b[1;32m    308\u001b[0m             demo_candidates[\u001b[38;5;28mid\u001b[39m(module_p)]\u001b[38;5;241m.\u001b[39mappend(candidate_p\u001b[38;5;241m.\u001b[39mdemos)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Generate N candidate prompts\u001b[39;00m\n\u001b[0;32m--> 311\u001b[0m instruction_candidates, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_first_N_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemo_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Initialize variables to store the best program and its score\u001b[39;00m\n\u001b[1;32m    314\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-inf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/dspy/teleprompt/signature_opt_bayesian.py:210\u001b[0m, in \u001b[0;36mBayesianSignatureOptimizer._generate_first_N_candidates\u001b[0;34m(self, module, N, view_data, view_examples, demo_candidates, devset)\u001b[0m\n\u001b[1;32m    208\u001b[0m     basic_prefix \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mextended_signature\u001b[38;5;241m.\u001b[39mfields[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     basic_instruction \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended_signature1\u001b[49m\u001b[38;5;241m.\u001b[39minstructions\n\u001b[1;32m    211\u001b[0m     basic_prefix \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mextended_signature1\u001b[38;5;241m.\u001b[39mfields[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_model: \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Predict' object has no attribute 'extended_signature1'"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BayesianSignatureOptimizer\n",
    "\n",
    "llm_prompter = dspy.OpenAI(model=\"gpt-3.5-turbo\", max_tokens=1000, model_type=\"chat\")\n",
    "teleprompter = BayesianSignatureOptimizer(task_model=dspy.settings.lm,\n",
    "                                        metric = llm_metric,\n",
    "                                        prompt_model=llm_prompter,\n",
    "                                        n=5,\n",
    "                                        verbose=False)\n",
    "kwargs = dict(num_threads=1, display_progress=True, display_table=0)\n",
    "third_compiled_rag = teleprompter.compile(RAG(), devset=devset,\n",
    "                                optuna_trials_num=3,\n",
    "                                max_bootstrapped_demos=4,\n",
    "                                max_labeled_demos=4,\n",
    "                                eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.31.1-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (6.7.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (1.25.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (12.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (2.31.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (4.10.0)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (3.1.31)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from streamlit) (6.1)\n",
      "Collecting watchdog>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl.metadata (37 kB)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2023.5.7)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading streamlit-1.31.1-py2.py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: watchdog, tzlocal, toolz, toml, tenacity, mdurl, pydeck, markdown-it-py, rich, altair, streamlit\n",
      "Successfully installed altair-5.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 pydeck-0.8.1b0 rich-13.7.0 streamlit-1.31.1 tenacity-8.2.3 toml-0.10.2 toolz-0.12.1 tzlocal-5.2 watchdog-4.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'test' has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtest\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run the content of the converted Python script\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'test' has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "# example.py\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "# Add a title\n",
    "st.title(\"My Jupyter Notebook\")\n",
    "\n",
    "# Import the converted Python script here\n",
    "import test\n",
    "\n",
    "# Run the content of the converted Python script\n",
    "test.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
